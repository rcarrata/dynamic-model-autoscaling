{{- if .Values.servingRuntime.enabled }}
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: {{ include "granite-3-3-8b.fullname" . }}
  labels:
    {{- include "granite-3-3-8b.labels" . | nindent 4 }}
spec:
  annotations:
    {{- with .Values.servingRuntime.annotations }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
  supportedModelFormats:
  - name: vLLM
    autoSelect: true
  - name: huggingface
    autoSelect: true
  multiModel: false
  containers:
  - name: kserve-container
    image: {{ .Values.servingRuntime.image | default "quay.io/modh/vllm:rhoai-2.22-cuda-5e9c649953464aa3a668aba1774e42fc933f721b" }}
    command:
      - python
      - '-m'
      - vllm.entrypoints.openai.api_server
    args:
      - '--port=8080'
      - '--model=/mnt/models'
    env:
    - name: HF_HOME
      value: {{ .Values.env.HF_HOME | default "/tmp/hf_home" }}
    {{- range $key, $value := .Values.env }}
    {{- if ne $key "HF_HOME" }}
    - name: {{ $key }}
      value: {{ $value | quote }}
    {{- end }}
    {{- end }}
    ports:
    - containerPort: 8080
      protocol: TCP
      name: http
    volumeMounts:
    - mountPath: /dev/shm
      name: shm
  volumes:
  - name: shm
    emptyDir:
      medium: Memory
      sizeLimit: {{ .Values.servingRuntime.shmSizeLimit | default "2Gi" }}
  {{- with .Values.nodeSelector }}
  nodeSelector:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.affinity }}
  affinity:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.tolerations }}
  tolerations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
{{- end }}
